# 전처리

학습 데이터인 TRAIN_A, TRAIN_B 두개의 파일은 각 파일당 한달의 데이터가 포함되어있는 반면, 테스트해야할 TEST_C와 TEST_D는 각 파일당 일주일의 데이터가 포함되어있기에 학습 데이터와 테스트 데이터의 일관성을 유기하기 위해서 학습 데이터도 일주일 단위로 잘랐습니다.

단, 학습 데이터의 갯수가 굉장히 적기 때문에 슬라이딩 윈도우 형식으로 Stride(step)를 적용해서 여러개의 데이터를 확보했습니다. 

그리고 학습 데이터 내에서도 이상 데이터는 굉장히 적기 때문에 이상 데이터는 과감하게 포기하고 정상 데이터만으로 학습을 시켜서 Threshold를 적용해 이상치를 감지하는 방식으로 진행하기로 계획하여, 전처리를 할 때 윈도우 내에 anomaly가 포함되어 있거나, 해당 윈도우의 마지막 시점에서 가까운 미래에 anomaly가 있다면 해당 윈도우를 데이터에서 제외하도록 설정했습니다.

그리고 데이터 내에 Q,M,P 세가지 종류의 센서가 존재하는데, 이 중 M센서인 펌프같은 경우에는 관망구조 내에서도 모든 펌프가 하나의 펌프 스테이션에 모여있으며, 작동 여부를 0과 1로만 나타내기 때문에 각 펌프끼리 같은 특성을 유지하고 있는 것으로 보여 몇 개의 펌프가 1로 작동되어있는지만 세어서 하나의 칼럼(M_sum)으로 통합했습니다.


# 모델 학습 전략

모델의 목표는 윈도우 내에 압력 센서(P)에서의 이상 발생 여부(P_flag)를 예측하는 것이며 그것 뿐만이 아니라 어느 센서에서 이상이 발생했는지 까지 그 위치까지 특정해야합니다.

Pn의 Pn_flag를 예측해야하는 작업이기 때문에 안 그래도 데이터의 종류가 적은데 데이터를 그대로 넣어버린다면 칼럼의 순서를 특징으로 학습해버릴 것이 우려되어서 P센서를 기준으로 데이터를 쪼개기로 했습니다.

예를 들어

(Q1, Q2, Q3, M_sum, P1, P2, P3) 라는 칼럼을 가진 데이터가 있다면

(Q1, Q2, Q3, M_sum, P1), (Q1, Q2, Q3, M_sum, P2), (Q1, Q2, Q3, M_sum, P3) 와 같이 나누는 식으로 각 P센서마다 개별적으로 추론할 수 있도록 진행했습니다.

그리고 펌프(M)의 경우 각 펌프끼리 같은 특성을 유지하고 있는 것으로 보이나, 유량 센서(Q)와 압력 센서(P)의 경우 각 센서끼리도 다른 특성을 보이는 것으로 보였습니다.

그렇다면 하나의 모델에 학습을 시킨다면 그 특성을 제대로 학습하기 어려울 것으로 예상되어 쪼개진 각 데이터별로 특성을 분석해 비슷한 특성을 가진 데이터끼리 Clustering(군집화)를 적용시켜 각 클러스터별로 모델을 분리해서 클러스터 내의 데이터는 한 모델로만 학습을 시켰습니다.

## 실루엣 계수 확인

센서의 특징으로 클러스터링을 통해 클러스터 나눈다는 전략에서, 클러스터의 갯수를 정하기 위해서 데이터의 실루엣 스코어를 계산해보았습니다.

![Image](https://github.com/user-attachments/assets/9f80f1f0-3c11-4f4f-91bf-947bd2074d3d)
Best Clustering Method: K-means
Best Number of Clusters: 6

K-means, Hierarchical, Gaussian Mixture 이렇게 세가지 방법으로 실루엣 스코어를 계산해보았을 때, 종합적으로 클러스터를 6개로 나누는 것이 가장 좋을 것으로 판단되어 클러스터의 갯수(n_cluster)를 6으로 설정했습니다.

추가적으로 왜 6개로 나눠졌는지 자세히 확인하기 위해 그래프로 특성 분포를 확인해보았습니다.
    
![Image](https://github.com/user-attachments/assets/5201ab24-70db-4142-ad5d-b69e703aa30b)


# 모델 학습

## 데이터 준비

1. **`prepare_data_by_sensor`** 함수로 각 센서(P 센서 기준)의 데이터를 개별적으로 전처리하고 정렬
2. 데이터 정규화 (Z-Score)
3. 시간순으로 정렬된 데이터 생성 및 센서별 특징 계산.

## 클러스터링

1. **`SensorClusterManager`**를 통해 K-means 알고리즘으로 클러스터링
2. 각 센서를 클러스터에 할당하고 센서별 클러스터 매핑 결과 저장

## 오버 샘플링

1. **`train_cluster_models()`** 함수에서 각 클러스터의 데이터량을 계산합니다.
2. 가장 많은 데이터를 가진 클러스터를 기준으로 데이터 크기가 적은 클러스터에 대해 오버 샘플링을 적용하여 데이터 크기를 맞춥니다.
3. 오버샘플링으로 인한 과적합을 방지하기 위해 데이터에 Gaussian 노이즈를 추가하여 데이터 다양성을 높입니다.

## **모델 구성 및 학습**

1. LSTM 기반의 Autoencoder 모델 정의
2. 입력 데이터를 latent 벡터로 인코딩 후 복원하는 구조
3. 손실 함수는 Q, M, P 센서 각각에 가중치를 부여해 계산

데이터를 P센서를 기준으로 쪼갰기 때문에 각 데이터마다 Q,와 M 칼럼은 공통적으로 들어가지만 P센서 칼럼은 각각 다르게 들어가기 때문에 P센서의 데이터에 가중치를 추가해서 학습시켰습니다.

## 임계값 설정

1. 테스트 데이터의 재구성 오차 분포를 기반으로 각 클러스터별로 백분위 100 지점을 임계값(Threshold)로 설정하여 학습한 데이터는 전부 정상데이터로 판단할 수 있도록 함

## 학습 결과

```markdown
Cluster 0 Stats:
Mean Error: 0.150499
Threshold: 0.448320
Best Validation Loss: 0.278797

Cluster 1 Stats:
Mean Error: 0.287713
Threshold: 0.967989
Best Validation Loss: 0.272267

Cluster 2 Stats:
Mean Error: 0.194099
Threshold: 0.526708
Best Validation Loss: 0.316725

Cluster 3 Stats:
Mean Error: 0.072300
Threshold: 0.225586
Best Validation Loss: 0.139579

Cluster 4 Stats:
Mean Error: 0.256126
Threshold: 0.880269
Best Validation Loss: 0.353070

Cluster 5 Stats:
Mean Error: 0.310722
Threshold: 1.068188
Best Validation Loss: 0.385324
```

Validation Loss가 평균 0.29096으로 나왔습니다.


# 테스트 데이터 분포 확인

테스트 데이터들이 학습 데이터로 클러스터링한 클러스터들 중에 어디에 얼마나 속해있는지, 그 분포는 어떻게 되는지 확인해봤습니다.

![Image](https://github.com/user-attachments/assets/a3437e40-7817-435a-a93e-4c409ab53eee)

![Image](https://github.com/user-attachments/assets/138643d7-4fbf-4f5a-835e-1dbefd886409)


# 임계값 조정을 통한 추론(Inference)

각각 TEST_C,  TEST_D로 구분하고, 그 안에서도 각각의 클러스터마다 다른 임계값을 정해보았습니다

임계값(Threshold)는 데이터 분포를 보고 정해보았습니다

제출해보았을 때 점수는 0.0080064051 으로 처참한 결과였습니다.
