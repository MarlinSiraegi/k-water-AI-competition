{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "train_path = './aggregated_7_480/'\n",
    "output_path = './prepared_data/'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "MAX_Q_SENSORS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_pattern(data, minutes_per_day=1440):\n",
    "    daily_data = data[:minutes_per_day].mean(axis=1)\n",
    "    return daily_data.std()\n",
    "\n",
    "def compute_weekly_pattern(data, minutes_per_week=10080):\n",
    "    if len(data) >= minutes_per_week:\n",
    "        weekly_data = data[:minutes_per_week].mean(axis=1)\n",
    "        return weekly_data.std()\n",
    "    return 0\n",
    "\n",
    "def calculate_global_stats(path):\n",
    "    q_values = []\n",
    "    p_values = []\n",
    "    m_values = []\n",
    "\n",
    "    file_list = glob(os.path.join(path, '*.csv'))\n",
    "    for file in file_list:\n",
    "        df = pd.read_csv(file)\n",
    "        q_sensors = [col for col in df.columns if col.startswith('Q')]\n",
    "        p_sensors = [col for col in df.columns if col.startswith('P') and not col.endswith('_flag')]\n",
    "\n",
    "        q_values.extend(df[q_sensors].values.flatten())\n",
    "        p_values.extend(df[p_sensors].values.flatten())\n",
    "        m_sum = df[[col for col in df.columns if col.startswith('M')]].sum(axis=1)\n",
    "        m_values.extend(m_sum.values)\n",
    "\n",
    "    q_mean, q_std = np.mean(q_values), np.std(q_values)\n",
    "    p_mean, p_std = np.mean(p_values), np.std(p_values)\n",
    "    m_mean, m_std = np.mean(m_values), np.std(m_values)\n",
    "\n",
    "    return {\n",
    "        \"Q\": {\"mean\": q_mean, \"std\": q_std},\n",
    "        \"P\": {\"mean\": p_mean, \"std\": p_std},\n",
    "        \"M_sum\": {\"mean\": m_mean, \"std\": m_std}\n",
    "    }\n",
    "\n",
    "def normalize_and_compute_features(df, max_q_sensors=MAX_Q_SENSORS):\n",
    "    # 각 칼럼별로 Z-Score 정규화\n",
    "    normalized_df = df.copy()\n",
    "    \n",
    "    q_sensors = [col for col in df.columns if col.startswith('Q')]\n",
    "    p_sensors = [col for col in df.columns if col.startswith('P') and not col.endswith('_flag')]\n",
    "    m_columns = [col for col in df.columns if col.startswith('M')]\n",
    "    \n",
    "    # 각 센서 타입별로 정규화\n",
    "    for sensor in q_sensors + p_sensors + m_columns:\n",
    "        normalized_df[sensor] = (df[sensor] - df[sensor].mean()) / (df[sensor].std() + 1e-8)\n",
    "    \n",
    "    # 정규화된 데이터로 피처 계산\n",
    "    padded_q_data = np.zeros((len(df), max_q_sensors))\n",
    "    \n",
    "    for idx, sensor in enumerate(q_sensors):\n",
    "        if idx >= max_q_sensors:\n",
    "            break\n",
    "        padded_q_data[:, idx] = normalized_df[sensor]\n",
    "    \n",
    "    m_sum = normalized_df[m_columns].sum(axis=1)\n",
    "\n",
    "    features = {\n",
    "        'mean': np.mean(padded_q_data, axis=0),\n",
    "        'std': np.std(padded_q_data, axis=0),\n",
    "        'skewness': pd.DataFrame(padded_q_data).skew().values,\n",
    "        'kurtosis': pd.DataFrame(padded_q_data).kurtosis().values,\n",
    "        'm_stats': {\n",
    "            'mean': np.mean(m_sum),\n",
    "            'std': np.std(m_sum),\n",
    "            'skewness': pd.Series(m_sum).skew(),\n",
    "            'kurtosis': pd.Series(m_sum).kurtosis()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    features.update({\n",
    "        'temporal': {\n",
    "            'autocorr': pd.Series(padded_q_data.mean(axis=1)).autocorr(),\n",
    "            'trend': np.polyfit(np.arange(len(padded_q_data)), \n",
    "                              padded_q_data.mean(axis=1), 1)[0],\n",
    "            'std_diff': np.std(np.diff(padded_q_data, axis=0)),\n",
    "            'daily_pattern': compute_daily_pattern(padded_q_data),\n",
    "            'weekly_pattern': compute_weekly_pattern(padded_q_data)\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return padded_q_data, m_sum, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesSensorDataset(Dataset):\n",
    "    def __init__(self, data, window_size=1440, stride=720):  # 하루 단위 윈도우, 12시간 스트라이드\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape [n_samples, n_features]\n",
    "            window_size: number of time steps in each window (default: 1440 minutes = 1 day)\n",
    "            stride: number of time steps to move forward (default: 720 minutes = 12 hours)\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.window_size) // self.stride + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.stride\n",
    "        window = self.data[start_idx:start_idx + self.window_size]\n",
    "        # 목표는 윈도우의 마지막 시점\n",
    "        target = self.data[start_idx + self.window_size - 1]\n",
    "        return window, target\n",
    "\n",
    "class TimeSeriesSensorAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32, hidden_dim=256, window_size=1440, weight_decay=1e-4, sensor_weights=None):\n",
    "        super(TimeSeriesSensorAutoencoder, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        if sensor_weights is None:\n",
    "            self.sensor_weights = {\n",
    "                'Q': 1.0,\n",
    "                'M': 0.5,\n",
    "                'P': 2.0\n",
    "            }\n",
    "        else:\n",
    "            self.sensor_weights = sensor_weights\n",
    "            \n",
    "        # 시계열 인코더 (LSTM 사용)\n",
    "        self.encoder_lstm = torch.nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # LSTM 출력을 latent space로 매핑\n",
    "        self.encoder_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim),  # *2는 bidirectional 때문\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(hidden_dim, latent_dim),\n",
    "            torch.nn.BatchNorm1d(latent_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # latent vector를 시계열 길이로 확장\n",
    "        self.decoder_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, hidden_dim),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # 시계열 디코더\n",
    "        self.decoder_lstm = torch.nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # 최종 출력층\n",
    "        self.output_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        device = x.device\n",
    "        \n",
    "        # 인코딩\n",
    "        lstm_out, _ = self.encoder_lstm(x)\n",
    "        # 마지막 시점의 출력만 사용\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        z = self.encoder_fc(last_hidden)\n",
    "        \n",
    "        # 디코딩\n",
    "        decoded = self.decoder_fc(z)\n",
    "        decoded = decoded.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        decoded, _ = self.decoder_lstm(decoded)\n",
    "        reconstructed = self.output_layer(decoded[:, -1, :])  # 마지막 시점만 예측\n",
    "        \n",
    "        # 마스크 생성 (마지막 시점에 대해서만)\n",
    "        q_mask = torch.zeros((batch_size, x.size(-1)), device=device)\n",
    "        q_mask[:, :MAX_Q_SENSORS] = (x[:, -1, :MAX_Q_SENSORS] != 0).float()\n",
    "        \n",
    "        m_mask = torch.zeros((batch_size, x.size(-1)), device=device)\n",
    "        m_mask[:, -2] = 1\n",
    "        \n",
    "        p_mask = torch.zeros((batch_size, x.size(-1)), device=device)\n",
    "        p_mask[:, -1] = 1\n",
    "        \n",
    "        # 손실 계산 (마지막 시점에 대해서만)\n",
    "        target = x[:, -1, :]\n",
    "        \n",
    "        q_loss = torch.nn.functional.mse_loss(\n",
    "            reconstructed * q_mask,\n",
    "            target * q_mask,\n",
    "            reduction='sum'\n",
    "        ) / (q_mask.sum() + 1e-8)\n",
    "        \n",
    "        m_loss = torch.nn.functional.mse_loss(\n",
    "            reconstructed * m_mask,\n",
    "            target * m_mask,\n",
    "            reduction='mean'\n",
    "        )\n",
    "        \n",
    "        p_loss = torch.nn.functional.mse_loss(\n",
    "            reconstructed * p_mask,\n",
    "            target * p_mask,\n",
    "            reduction='mean'\n",
    "        )\n",
    "        \n",
    "        total_loss = (\n",
    "            self.sensor_weights['Q'] * q_loss + \n",
    "            self.sensor_weights['M'] * m_loss + \n",
    "            self.sensor_weights['P'] * p_loss + \n",
    "            self.weight_decay * sum(p.norm(2) ** 2 for p in self.parameters())\n",
    "        )\n",
    "        \n",
    "        return z, reconstructed, total_loss\n",
    "\n",
    "class SensorClusterManager:\n",
    "    def __init__(self, n_clusters=6):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters)\n",
    "        self.cluster_models = {}\n",
    "        self.cluster_stats = {}\n",
    "        self.sensor_weights = {\n",
    "            'Q': 1.0,\n",
    "            'M': 0.5,\n",
    "            'P': 2.0\n",
    "        }\n",
    "        \n",
    "    def compute_cluster_assignment(self, sensor_data_dict):\n",
    "        p_values = []\n",
    "        sensor_ids = list(sensor_data_dict.keys())\n",
    "        \n",
    "        for sensor_id in sensor_ids:\n",
    "            # timestamp 열을 제외한 숫자 데이터만 사용\n",
    "            numeric_columns = sensor_data_dict[sensor_id].columns[:-1]  # timestamp 열 제외\n",
    "            p_mean = np.mean(sensor_data_dict[sensor_id][numeric_columns].values[:, -1])\n",
    "            p_values.append(p_mean)\n",
    "        \n",
    "        p_values = np.array(p_values).reshape(-1, 1)\n",
    "        feature_clusters = self.kmeans.fit_predict(p_values)\n",
    "        self.sensor_cluster_mapping = dict(zip(sensor_ids, feature_clusters))\n",
    "        \n",
    "        cluster_labels = []\n",
    "        for sensor_id in sensor_ids:\n",
    "            cluster_idx = self.sensor_cluster_mapping[sensor_id]\n",
    "            data_length = len(sensor_data_dict[sensor_id])\n",
    "            cluster_labels.extend([cluster_idx] * data_length)\n",
    "        \n",
    "        return np.array(cluster_labels)\n",
    "    \n",
    "    def train_cluster_models(self, sensor_data, input_dim, device, weight_decay=1e-4):\n",
    "        # 각 클러스터별 데이터 크기 파악\n",
    "        cluster_sizes = []\n",
    "        for cluster in range(self.n_clusters):\n",
    "            cluster_data = sensor_data[sensor_data['cluster'] == cluster]\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "        \n",
    "        max_size = max(cluster_sizes)\n",
    "\n",
    "        for cluster in range(self.n_clusters):\n",
    "            print(f\"\\nTraining model for cluster {cluster}\")\n",
    "            cluster_data = sensor_data[sensor_data['cluster'] == cluster]\n",
    "            if len(cluster_data) == 0:\n",
    "                continue\n",
    "\n",
    "            # 센서 ID를 기준으로 데이터 정렬하여 시계열 연속성 유지\n",
    "            cluster_data = cluster_data.sort_values(['sensor_id', 'timestamp'])\n",
    "            numeric_data = cluster_data.drop(['cluster', 'sensor_id', 'timestamp'], axis=1).values\n",
    "\n",
    "            # 일 단위 윈도우를 고려한 데이터 분할\n",
    "            window_size = 1440  # 1일\n",
    "            stride = 720       # 12시간\n",
    "            \n",
    "            total_windows = (len(numeric_data) - window_size) // stride + 1\n",
    "            train_size = int(0.8 * total_windows)\n",
    "            val_size = int(0.1 * total_windows)\n",
    "\n",
    "            # 데이터셋 생성\n",
    "            train_dataset = TimeSeriesSensorDataset(\n",
    "                numeric_data[:train_size * stride + window_size],\n",
    "                window_size=window_size,\n",
    "                stride=stride\n",
    "            )\n",
    "            val_dataset = TimeSeriesSensorDataset(\n",
    "                numeric_data[train_size * stride:train_size * stride + val_size * stride + window_size],\n",
    "                window_size=window_size,\n",
    "                stride=stride\n",
    "            )\n",
    "            test_dataset = TimeSeriesSensorDataset(\n",
    "                numeric_data[train_size * stride + val_size * stride:],\n",
    "                window_size=window_size,\n",
    "                stride=stride\n",
    "            )\n",
    "\n",
    "            # 배치 크기 조정\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=64, \n",
    "                shuffle=False,\n",
    "                num_workers=28,  # CPU 코어 수에 맞게 조정\n",
    "                pin_memory=True  # GPU 메모리 전송 최적화\n",
    "            )\n",
    "\n",
    "            val_dataloader = DataLoader(\n",
    "                val_dataset, \n",
    "                batch_size=64, \n",
    "                shuffle=False,\n",
    "                num_workers=28,\n",
    "                pin_memory=True\n",
    "            )\n",
    "\n",
    "            test_dataloader = DataLoader(\n",
    "                test_dataset, \n",
    "                batch_size=64, \n",
    "                shuffle=False,\n",
    "                num_workers=28,\n",
    "                pin_memory=True\n",
    "            )\n",
    "\n",
    "            # 모델 초기화\n",
    "            model = TimeSeriesSensorAutoencoder(\n",
    "                input_dim=input_dim,\n",
    "                window_size=window_size,\n",
    "                weight_decay=weight_decay,\n",
    "                sensor_weights=self.sensor_weights\n",
    "            ).to(device)\n",
    "            \n",
    "            # Learning rate 감소 (시계열 학습 안정성을 위해)\n",
    "            optimizer = Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            patience = 12\n",
    "            patience_counter = 0\n",
    "\n",
    "            for epoch in range(70):\n",
    "                model.train()\n",
    "                total_train_loss = 0\n",
    "                for windows, targets in tqdm(train_dataloader, desc=f\"Cluster {cluster}, Epoch {epoch+1} [Train]\", leave=False):\n",
    "                    windows, targets = windows.to(device), targets.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    z, reconstructed, total_loss = model(windows)\n",
    "\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_train_loss += total_loss.item()\n",
    "\n",
    "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "                model.eval()\n",
    "                total_val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for windows, targets in tqdm(val_dataloader, desc=f\"Cluster {cluster}, Epoch {epoch+1} [Val]\", leave=False):\n",
    "                        windows, targets = windows.to(device), targets.to(device)\n",
    "                        z, reconstructed, v_loss = model(windows)\n",
    "                        total_val_loss += v_loss.item()\n",
    "\n",
    "                avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "                if epoch % 5 == 0:\n",
    "                    print(f\"Cluster {cluster}, Epoch {epoch+1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = model.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # 테스트 단계\n",
    "            reconstruction_errors = []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for windows, targets in test_dataloader:\n",
    "                    windows, targets = windows.to(device), targets.to(device)\n",
    "                    z, reconstructed, _ = model(windows)\n",
    "                    \n",
    "                    # 마스크 생성 (마지막 시점에 대해서만)\n",
    "                    q_mask = torch.zeros_like(targets)\n",
    "                    q_mask[:, :MAX_Q_SENSORS] = (targets[:, :MAX_Q_SENSORS] != 0).float()\n",
    "                    \n",
    "                    m_mask = torch.zeros_like(targets)\n",
    "                    m_mask[:, -2] = 1\n",
    "                    \n",
    "                    p_mask = torch.zeros_like(targets)\n",
    "                    p_mask[:, -1] = 1\n",
    "                    \n",
    "                    combined_mask = q_mask + m_mask + p_mask\n",
    "                    \n",
    "                    errors = (torch.nn.functional.mse_loss(\n",
    "                        reconstructed,\n",
    "                        targets,\n",
    "                        reduction='none'\n",
    "                    ) * combined_mask).sum(dim=1) / combined_mask.sum(dim=1)\n",
    "\n",
    "                    reconstruction_errors.extend(errors.cpu().numpy())\n",
    "\n",
    "            # 통계 저장 및 임계값 계산\n",
    "            self.cluster_stats[cluster] = {\n",
    "                'threshold': np.percentile(reconstruction_errors, 95),  # 95 퍼센타일로 변경\n",
    "                'mean_error': np.mean(reconstruction_errors),\n",
    "                'std_error': np.std(reconstruction_errors),\n",
    "                'best_val_loss': best_val_loss\n",
    "            }\n",
    "\n",
    "            self.cluster_models[cluster] = model\n",
    "\n",
    "            print(f\"\\nCluster {cluster} Stats:\")\n",
    "            print(f\"Mean Error: {self.cluster_stats[cluster]['mean_error']:.6f}\")\n",
    "            print(f\"Threshold: {self.cluster_stats[cluster]['threshold']:.6f}\")\n",
    "            print(f\"Best Validation Loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def prepare_data_by_sensor(path, max_q_sensors=MAX_Q_SENSORS):\n",
    "    file_list = glob(os.path.join(path, '*.csv'))\n",
    "    sensor_data = {}\n",
    "    sensor_features = {}\n",
    "\n",
    "    for file in tqdm(file_list, desc=\"Processing files\", leave=False):\n",
    "        df = pd.read_csv(file)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], format='%y/%m/%d %H:%M')\n",
    "        \n",
    "        padded_q_data, m_data = None, None\n",
    "        p_sensors = [col for col in df.columns if col.startswith('P') and not col.endswith('_flag')]\n",
    "\n",
    "        for p_sensor in p_sensors:\n",
    "            if padded_q_data is None:\n",
    "                padded_q_data, m_data, features = normalize_and_compute_features(\n",
    "                    df, max_q_sensors\n",
    "                )\n",
    "            \n",
    "            # timestamp를 제외한 숫자 데이터만 저장\n",
    "            combined_data = np.concatenate([\n",
    "                padded_q_data, \n",
    "                m_data.values[:, np.newaxis],\n",
    "                df[p_sensor].values[:, np.newaxis]\n",
    "            ], axis=1)\n",
    "            \n",
    "            sensor_id = f\"{'TRAIN_A' if 'TRAIN_A' in file else 'TRAIN_B'}_{p_sensor}\"\n",
    "            if sensor_id not in sensor_data:\n",
    "                sensor_data[sensor_id] = []\n",
    "                sensor_features[sensor_id] = []\n",
    "            \n",
    "            # DataFrame으로 변환할 때 timestamp는 따로 저장\n",
    "            data_df = pd.DataFrame(combined_data)\n",
    "            data_df['timestamp'] = df['timestamp']  # timestamp를 마지막 열로 추가\n",
    "            sensor_data[sensor_id].append(data_df)\n",
    "            sensor_features[sensor_id].append(features)\n",
    "\n",
    "    # 각 센서별로 시간순 정렬된 데이터 생성\n",
    "    for sensor_id in sensor_data:\n",
    "        sensor_data[sensor_id] = pd.concat(sensor_data[sensor_id], axis=0)\n",
    "        sensor_data[sensor_id] = sensor_data[sensor_id].sort_values('timestamp')\n",
    "\n",
    "    return sensor_data, sensor_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# 메인 실행 코드\n",
    "print(\"Starting data processing...\")\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "sensor_data, sensor_features = prepare_data_by_sensor(train_path)\n",
    "\n",
    "print(\"\\nProcessing all sensors...\")\n",
    "cluster_manager = SensorClusterManager(n_clusters=6)\n",
    "\n",
    "# 클러스터링 수행\n",
    "cluster_labels = cluster_manager.compute_cluster_assignment(sensor_data)\n",
    "\n",
    "# 데이터프레임 생성 및 클러스터 할당\n",
    "all_data = []\n",
    "for sensor_id in sensor_data:\n",
    "    df = sensor_data[sensor_id].copy()\n",
    "    df['sensor_id'] = sensor_id\n",
    "    all_data.append(df)\n",
    "\n",
    "df_combined = pd.concat(all_data, axis=0)\n",
    "df_combined['cluster'] = cluster_labels\n",
    "\n",
    "print(\"\\nSensor Cluster Assignments:\")\n",
    "for sensor_id, cluster in cluster_manager.sensor_cluster_mapping.items():\n",
    "    print(f\"{sensor_id}: Cluster {cluster}\")\n",
    "\n",
    "# 모델 학습\n",
    "cluster_manager.train_cluster_models(\n",
    "    df_combined, \n",
    "    input_dim=MAX_Q_SENSORS + 2, \n",
    "    device=device  # window_size는 이미 train_cluster_models 안에서 1440으로 설정됨\n",
    ")\n",
    "\n",
    "# 결과 저장\n",
    "torch.save({\n",
    "    'cluster_models': cluster_manager.cluster_models,\n",
    "    'cluster_stats': cluster_manager.cluster_stats,\n",
    "    'kmeans': cluster_manager.kmeans,\n",
    "    'sensor_cluster_mapping': cluster_manager.sensor_cluster_mapping\n",
    "}, os.path.join(output_path, 'time_series_cluster_models.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 - 클러스터링 결과\n",
    "plt.figure(figsize=(15, 5))\n",
    "sensor_means = {}\n",
    "for sensor_id in sensor_data:\n",
    "    sensor_means[sensor_id] = np.mean(sensor_data[sensor_id].iloc[:, -1])\n",
    "\n",
    "colors = plt.cm.get_cmap('tab20')(np.linspace(0, 1, cluster_manager.n_clusters))\n",
    "\n",
    "for cluster in range(cluster_manager.n_clusters):\n",
    "    cluster_sensors = [s for s, c in cluster_manager.sensor_cluster_mapping.items() if c == cluster]\n",
    "    cluster_means = [sensor_means[s] for s in cluster_sensors]\n",
    "    x_positions = range(len(cluster_sensors))\n",
    "    plt.scatter(x_positions, \n",
    "                cluster_means,\n",
    "                c=[colors[cluster]],\n",
    "                label=f'Cluster {cluster}')\n",
    "    plt.xticks(x_positions, cluster_sensors, rotation=45, ha='right')\n",
    "\n",
    "plt.title('Average P Sensor Values by Cluster')\n",
    "plt.ylabel('Normalized P Sensor Value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클러스터별 시계열 패턴 시각화\n",
    "for cluster in range(cluster_manager.n_clusters):\n",
    "    cluster_data = df_combined[df_combined['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} contains sensors:\")\n",
    "    print(sorted(cluster_data['sensor_id'].unique()))\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Q1 센서 시계열\n",
    "    plt.subplot(3, 1, 1)\n",
    "    for sensor_id in sorted(cluster_data['sensor_id'].unique()):\n",
    "        sensor_data = cluster_data[cluster_data['sensor_id'] == sensor_id]\n",
    "        plt.plot(sensor_data['timestamp'], sensor_data.iloc[:, 0], \n",
    "                label=sensor_id, alpha=0.5)\n",
    "    plt.title(f'Q1 Sensor Time Series for Cluster {cluster}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Q1 Value')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # M_sum 시계열\n",
    "    plt.subplot(3, 1, 2)\n",
    "    for sensor_id in sorted(cluster_data['sensor_id'].unique()):\n",
    "        sensor_data = cluster_data[cluster_data['sensor_id'] == sensor_id]\n",
    "        plt.plot(sensor_data['timestamp'], sensor_data.iloc[:, -2], \n",
    "                label=sensor_id, alpha=0.5)\n",
    "    plt.title(f'M_sum Time Series for Cluster {cluster}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('M_sum Value')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # P 센서 시계열\n",
    "    plt.subplot(3, 1, 3)\n",
    "    for sensor_id in sorted(cluster_data['sensor_id'].unique()):\n",
    "        sensor_data = cluster_data[cluster_data['sensor_id'] == sensor_id]\n",
    "        plt.plot(sensor_data['timestamp'], sensor_data.iloc[:, -1], \n",
    "                label=sensor_id, alpha=0.5)\n",
    "    plt.title(f'P Sensor Time Series for Cluster {cluster}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('P Value')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 재구성 오차 분포 시각화\n",
    "    if cluster in cluster_manager.cluster_stats:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        threshold = cluster_manager.cluster_stats[cluster]['threshold']\n",
    "        mean_error = cluster_manager.cluster_stats[cluster]['mean_error']\n",
    "        plt.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.4f}')\n",
    "        plt.axvline(x=mean_error, color='g', linestyle='--', label=f'Mean Error: {mean_error:.4f}')\n",
    "        plt.title(f'Reconstruction Error Distribution for Cluster {cluster}')\n",
    "        plt.xlabel('Reconstruction Error')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nTraining and visualization completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yangpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
